{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23099241-c15b-4e26-bbcd-c153aa282da3",
   "metadata": {},
   "source": [
    "# Evaluación PYTHON + DATA\n",
    "### Miguel Ángel Fuentes Valenzuela | miguel.fuentes.valenzuela@nter.es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73aacd54-1f2a-439b-9f53-f96d40a887f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests as req\n",
    "import zipfile as zipf\n",
    "import pandas as pd\n",
    "import logging as log\n",
    "\n",
    "#Librerias extra que también uso:\n",
    "from unidecode import unidecode\n",
    "import sys\n",
    "import os\n",
    "import io\n",
    "\n",
    "output_path = \"output\"\n",
    "api_url = \"https://portal.mineco.gob.es/economiayempresa/EconomiaInformesMacro/Documents/bdsicecsv.zip\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e8a3b8f-1ea3-4a44-bf23-b21c634033a1",
   "metadata": {},
   "source": [
    "## Primero, configuraremos el módulo Logging que vamos a usar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "308269ae-a4b7-40d4-8779-672ab7ee4b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ev_logger = log.getLogger(\"ev_logger\")\n",
    "\n",
    "# Configurar el modo del logger a 'DEBUG' y los manejadores de ficheros que almacenarán los logs\n",
    "ev_logger.setLevel(log.DEBUG)\n",
    "\n",
    "\n",
    "# Dar formato a los fileHandler's mediante un objeto logging.Formatter y el FileHandler\n",
    "formateador = log.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "fhand_Critical = log.FileHandler(\"logFile.log\")\n",
    "fhand_Critical.setFormatter(formateador)\n",
    "\n",
    "# Especificar nivel de los fileHandler's\n",
    "fhand_Critical.setLevel(log.DEBUG)\n",
    "# Aplicar el fileHandler a los logger's\n",
    "ev_logger.addHandler(fhand_Critical)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf72c8ef-9f5d-422d-afae-63bc95134b32",
   "metadata": {},
   "source": [
    "## A continuación, obtendremos de la API el .zip requerido\n",
    "### Para ello, usaremos una petición GET (y aprovecho una función que ya tenía guardada del Día 9 (uso de APIs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0789404d-6aa6-4cd1-a324-dc050892d5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conectarYComprobar(url: str, parm: dict=None, headrs: dict=None):\n",
    "    '''\n",
    "    Hace una petición GET a la url indicada; devuelve la respuesta del servidor\n",
    "    y hace print por pantalla del código HTTP devuelto tras hacer\n",
    "    la petición.\n",
    "    '''\n",
    "    print(\"Petición enviada! Recbiendo respuesta...\")\n",
    "    if (parm is not None and headrs is not None):\n",
    "        response = req.get(url, params=parm, headers=headrs, verify=False)\n",
    "    elif (parm is not None):\n",
    "        response = req.get(url, parm, verify=False)\n",
    "    else:\n",
    "        response = req.get(url, verify=False) # Debemos utilizar verify=False, porque sino nos obligará a verificar el certificado SSL en este caso\n",
    "    \n",
    "    print(f\"Codigo de respuesta para {url}: {response.status_code}\")\n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32610985-5d40-4402-bff5-fc262901f663",
   "metadata": {},
   "source": [
    "La API es la siguiente:<b> https://portal.mineco.gob.es/economiayempresa/EconomiaInformesMacro/Documents/bdsicecsv.zip </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5edd456c-fbd0-41c6-9a7b-0ac59bf96750",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Petición enviada! Recbiendo respuesta...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\miguel.fuentes.vale\\AppData\\Local\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:1100: InsecureRequestWarning: Unverified HTTPS request is being made to host 'portal.mineco.gob.es'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "C:\\Users\\miguel.fuentes.vale\\AppData\\Local\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:1100: InsecureRequestWarning: Unverified HTTPS request is being made to host 'bdsice.mineco.gob.es'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Codigo de respuesta para https://portal.mineco.gob.es/economiayempresa/EconomiaInformesMacro/Documents/bdsicecsv.zip: 200\n"
     ]
    }
   ],
   "source": [
    "resp = None\n",
    "\n",
    "try:\n",
    "    ev_logger.log(log.WARNING, f\"Intentando conectar a la API [{api_url}]...\")\n",
    "    resp = conectarYComprobar(api_url)\n",
    "except:\n",
    "    ev_logger.log(log.ERROR, f\"FALLÓ AL CONECTAR! Intento de conexión a [{api_url}]\")\n",
    "    sys.exit(1)\n",
    "\n",
    "try:\n",
    "    ev_logger.log(log.WARNING, f\"Datos encontrados! Comenzando extracción del fichero ZIP...\")\n",
    "    #Ahora, usare zipfile para obtener los ficheros CSV de la descarga\n",
    "    zipDescarga = zipf.ZipFile(io.BytesIO(resp.content))\n",
    "    #Crear la carpeta si no existe antes\n",
    "    if (\"output\" not in os.listdir()):\n",
    "        os.mkdir(\"output\")\n",
    "    zipDescarga.extractall(\"output/\") #extraer con ZipFile en la carpeta indicada\n",
    "    ev_logger.log(log.WARNING, \"Hecho! Ficheros extraidos correctamente!\")\n",
    "except:\n",
    "    ev_logger.log(log.ERROR, f\"FALLÓ AL EXTRAER!\")\n",
    "    sys.exit(1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feaade74-7e17-4177-a07e-3e9cd0c3b1cd",
   "metadata": {},
   "source": [
    "## Ahora, obtendremos los CSV pertenecientes a los códigos que necesitamos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e5be8532-c5c6-466c-a80a-dd5191638d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cons_cemento = \"236000.CSV\"\n",
    "cons_viviendas = \"232020.CSV\"\n",
    "remun_personal = \"715100.CSV\"\n",
    "pobl_parada = \"170000n.CSV\"\n",
    "\n",
    "ficheros = [cons_cemento, cons_viviendas, remun_personal, pobl_parada]\n",
    "ficheros_dir = os.listdir(\"output/\")\n",
    "# comprobar que existen\n",
    "for fichero in ficheros:\n",
    "    if fichero not in ficheros_dir:\n",
    "        print(\"El fichero necesario \" + fichero + \" no está en el directorio de salida!\")\n",
    "\n",
    "#Mediante la librería Pandas, los almacenaremos en diferentes dataframes\n",
    "## De esta manera, será mas facil limpiar datos y sacar info. relevante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1ee822e1-4ed4-4cd0-bf80-9fba18ee9f58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      annus   mes               observaciones  código  título  unidad  fuente  \\\n",
      "716  2023.0   9.0                  1138,35300     NaN     NaN     NaN     NaN   \n",
      "717  2023.0  10.0                  1197,29300     NaN     NaN     NaN     NaN   \n",
      "718  2023.0  11.0                  1290,45000     NaN     NaN     NaN     NaN   \n",
      "719  2023.0  12.0                  1059,28600     NaN     NaN     NaN     NaN   \n",
      "720  2024.0   1.0                  1055,77200     NaN     NaN     NaN     NaN   \n",
      "721  2024.0   2.0                  1168,89000     NaN     NaN     NaN     NaN   \n",
      "722  2024.0   3.0                  1100,84200     NaN     NaN     NaN     NaN   \n",
      "723  2024.0   4.0                  1286,08800     NaN     NaN     NaN     NaN   \n",
      "724  2024.0   5.0                  1311,67900     NaN     NaN     NaN     NaN   \n",
      "725     NaN   NaN                         NaN     NaN     NaN     NaN     NaN   \n",
      "\n",
      "     notas  \n",
      "716    NaN  \n",
      "717    NaN  \n",
      "718    NaN  \n",
      "719    NaN  \n",
      "720    NaN  \n",
      "721    NaN  \n",
      "722    NaN  \n",
      "723    NaN  \n",
      "724    NaN  \n",
      "725    NaN  \n",
      "      annus   mes               observaciones  código  título  unidad  fuente  \\\n",
      "234  2023.0   7.0                  7068,00000     NaN     NaN     NaN     NaN   \n",
      "235  2023.0   8.0                  8291,00000     NaN     NaN     NaN     NaN   \n",
      "236  2023.0   9.0                 10364,00000     NaN     NaN     NaN     NaN   \n",
      "237  2023.0  10.0                 11494,00000     NaN     NaN     NaN     NaN   \n",
      "238  2023.0  11.0                  7461,00000     NaN     NaN     NaN     NaN   \n",
      "239  2023.0  12.0                  9329,00000     NaN     NaN     NaN     NaN   \n",
      "240  2024.0   1.0                  8409,00000     NaN     NaN     NaN     NaN   \n",
      "241  2024.0   2.0                 10216,00000     NaN     NaN     NaN     NaN   \n",
      "242  2024.0   3.0                  8106,00000     NaN     NaN     NaN     NaN   \n",
      "243     NaN   NaN                         NaN     NaN     NaN     NaN     NaN   \n",
      "\n",
      "     notas  \n",
      "234    NaN  \n",
      "235    NaN  \n",
      "236    NaN  \n",
      "237    NaN  \n",
      "238    NaN  \n",
      "239    NaN  \n",
      "240    NaN  \n",
      "241    NaN  \n",
      "242    NaN  \n",
      "243    NaN  \n",
      "      annus   mes               observaciones  código  título  unidad  fuente  \\\n",
      "573  2023.0   9.0                 14380,11500     NaN     NaN     NaN     NaN   \n",
      "574  2023.0  10.0                 15969,50100     NaN     NaN     NaN     NaN   \n",
      "575  2023.0  11.0                 17509,51200     NaN     NaN     NaN     NaN   \n",
      "576  2023.0  12.0                 20145,18100     NaN     NaN     NaN     NaN   \n",
      "577  2024.0   1.0                  1347,45900     NaN     NaN     NaN     NaN   \n",
      "578  2024.0   2.0                  3048,52700     NaN     NaN     NaN     NaN   \n",
      "579  2024.0   3.0                  4694,00200     NaN     NaN     NaN     NaN   \n",
      "580  2024.0   4.0                  6255,66300     NaN     NaN     NaN     NaN   \n",
      "581  2024.0   5.0                  7780,12000     NaN     NaN     NaN     NaN   \n",
      "582     NaN   NaN                         NaN     NaN     NaN     NaN     NaN   \n",
      "\n",
      "     notas  \n",
      "573    NaN  \n",
      "574    NaN  \n",
      "575    NaN  \n",
      "576    NaN  \n",
      "577    NaN  \n",
      "578    NaN  \n",
      "579    NaN  \n",
      "580    NaN  \n",
      "581    NaN  \n",
      "582    NaN  \n",
      "      annus   mes               observaciones código  título  unidad  fuente  \\\n",
      "333  2023.0  10.0                  2759,40400    NaN     NaN     NaN     NaN   \n",
      "334  2023.0  11.0                  2734,83100    NaN     NaN     NaN     NaN   \n",
      "335  2023.0  12.0                  2707,45600    NaN     NaN     NaN     NaN   \n",
      "336  2024.0   1.0                  2767,86000    NaN     NaN     NaN     NaN   \n",
      "337  2024.0   2.0                  2760,40800    NaN     NaN     NaN     NaN   \n",
      "338  2024.0   3.0                  2727,00300    NaN     NaN     NaN     NaN   \n",
      "339  2024.0   4.0                  2666,50000    NaN     NaN     NaN     NaN   \n",
      "340  2024.0   5.0                  2607,85000    NaN     NaN     NaN     NaN   \n",
      "341  2024.0   6.0                  2561,06700    NaN     NaN     NaN     NaN   \n",
      "342     NaN   NaN                         NaN    NaN     NaN     NaN     NaN   \n",
      "\n",
      "     notas  \n",
      "333    NaN  \n",
      "334    NaN  \n",
      "335    NaN  \n",
      "336    NaN  \n",
      "337    NaN  \n",
      "338    NaN  \n",
      "339    NaN  \n",
      "340    NaN  \n",
      "341    NaN  \n",
      "342    NaN  \n"
     ]
    }
   ],
   "source": [
    "df_listado = list()\n",
    "for fichero in ficheros:\n",
    "    df = pd.read_csv(\"output/\" + fichero, sep=\";\", encoding=\"ISO-8859-1\", na_values=\"null\")\n",
    "    df.name = fichero\n",
    "    df_listado.append(df)\n",
    "\n",
    "#comprobar que se han guardado correctamente; Mostrando las 10 primeras filas de cada df\n",
    "for df in df_listado:\n",
    "    print(df.tail(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1276f5ae-3624-4f8c-b238-585f8c3c0a60",
   "metadata": {},
   "source": [
    "## Limpieza y tratado de datos con Pandas\n",
    "\n",
    "### Primero las columnas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "abededcf-8796-4750-b4fd-66a759fdc0ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    annus  mes               observaciones    codigo  \\\n",
      "0  1964.0  1.0                   787,10000  236000.0   \n",
      "\n",
      "                      titulo              unidad                   fuente  \\\n",
      "0  CEMENTO. CONSUMO APARENTE  MILES DE TONELADAS  MINISTERIO DE INDUSTRIA   \n",
      "\n",
      "                                               notas  \n",
      "0  https://industria.gob.es/es-es/estadisticas/pa...  \n",
      "    annus  mes               observaciones    codigo  \\\n",
      "0  2004.0  1.0                 50657,00000  232020.0   \n",
      "\n",
      "                                             titulo    unidad  \\\n",
      "0  VIVIENDAS INICIADAS. TOTAL (LIBRES Y PROTEGIDAS)  UNIDADES   \n",
      "\n",
      "                  fuente                                              notas  \n",
      "0  MINISTERIO DE FOMENTO  Vivienda libre y protegida  (www.mitma.es/el-m...  \n",
      "    annus   mes               observaciones    codigo  \\\n",
      "0  1975.0  12.0                          ND  715100.0   \n",
      "\n",
      "                                              titulo             unidad  \\\n",
      "0  ESTADO. CAJA. GASTOS.  OBLIG RECONOCIDAS. REMU...  MILLONES DE EUROS   \n",
      "\n",
      "   fuente                                              notas  \n",
      "0    IGAE  Ejecución presupuestaria mensual (Contabilidad...  \n",
      "    annus  mes               observaciones   codigo           titulo  unidad  \\\n",
      "0  1996.0  1.0                  2995,77400  170000n  PARO REGISTRADO   MILES   \n",
      "\n",
      "                  fuente                                              notas  \n",
      "0  MINISTERIO DE TRABAJO  www.sepe.es/HomeSepe/que-es-el-sepe/estadistic...  \n"
     ]
    }
   ],
   "source": [
    "#Para hacer limpieza respecto a los nombres de columnas, y estandarizarlos.\n",
    "## Usaré list comprehension, la librería unidecode y luego replace en pandas, para cambiar cualquier nombre de columnas con tilde en su caracter sin tilde\n",
    "try:\n",
    "    for df in df_listado:\n",
    "        columnas = df.columns.values\n",
    "        columnas_formateadas = [unidecode(nombre) for nombre in columnas] \n",
    "        # comprobando si es ascii un string, se sabe si tiene caractéres extraños (tildes, p.ejemplo) o no\n",
    "        # Info encontrada en: https://stackoverflow.com/questions/21843971/detecting-accents-in-words-python\n",
    "        # solución de unidecode = https://www.geeksforgeeks.org/transliterating-non-ascii-characters-with-python/\n",
    "        df.columns = columnas_formateadas\n",
    "except:\n",
    "    ev_logger.log(log.ERROR, \"FALLO al intentar renombrar columnas\")\n",
    "\n",
    "#comprobar que se han cambiado sus nombres correctamente\n",
    "for df in df_listado:\n",
    "    print(df.head(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6bf5e5b-478b-4118-b28c-7c58796cfc08",
   "metadata": {},
   "source": [
    "### Despues, limpieza de datos, y agregación de columnas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "34b21c49-3d17-4555-b3ab-d95b9621eac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "236000.CSV: \n",
      "                observaciones   fecha  valor\n",
      "0                   787,10000  1/1964  787.1\n",
      "232020.CSV: \n",
      "                observaciones   fecha    valor\n",
      "0                 50657,00000  1/2004  50657.0\n",
      "715100.CSV: \n",
      "               observaciones    fecha  valor\n",
      "0                          0  12/1975    0.0\n",
      "170000n.CSV: \n",
      "                observaciones   fecha   valor\n",
      "0                  2995,77400  1/1996  2995.8\n"
     ]
    }
   ],
   "source": [
    "# limpiar datos y dar formato correcto a las columnas\n",
    "for df in df_listado:\n",
    "    df[\"annus\"] = df[\"annus\"].fillna(0)\n",
    "    df[\"annus\"] = df[\"annus\"].astype('i')\n",
    "    df[\"mes\"] = df[\"mes\"].fillna(0)\n",
    "    df[\"mes\"] = df[\"mes\"].astype('i')\n",
    "    df[\"observaciones\"] = df[\"observaciones\"].fillna(0)\n",
    "\n",
    "    #Agregar las columnas requeridas con los datos ya limpios\n",
    "    #La fecha sera un string, tal y como se pide (paso las fechas a strings UNICODE)\n",
    "    df[\"fecha\"] = df[\"mes\"].astype('U') + \"/\" + df[\"annus\"].astype('U')\n",
    "    #\"valor\" sera los valores de 'observaciones' pero con un solo decimal. Los valores que no sean digitos se transformaran a 0.00\n",
    "    #Convertir todos los 'ND' a valor 0 numérico\n",
    "    df[\"observaciones\"] = df[\"observaciones\"].str.replace(\"ND\", \"0\")\n",
    "    df[\"valor\"] = df[\"observaciones\"].str.replace(\",\", \".\").astype('float').round(1)\n",
    "    print(df.name + \": \")\n",
    "    print(df[[\"observaciones\", \"fecha\", \"valor\"]].head(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "418b571a-63c2-4746-b99b-c74369654d2a",
   "metadata": {},
   "source": [
    "## Para terminar, exportar como ficheros CSV los dataframes tratados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ddf3396a-50d0-49b8-ab69-b56256f73c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pasar a CSV los ficheros necesarios\n",
    "#Para sus nombres de fichero, almaceno en un dict los codigos y su traducción necesaria según la tabla ConstruData dada en la evaluación:\n",
    "dict_traduccion = {\n",
    "    \"170000n.CSV\": \"PR-123\",\n",
    "    \"555R20.CSV\": \"IVUS-211\",\n",
    "    \"555R11.CSV\": \"IVUS-222\",\n",
    "    \"232020.CSV\": \"VI-01\",\n",
    "    \"236000.CSV\": \"CC-01\",\n",
    "    \"715100.CSV\": \"RP-01\",\n",
    "    \"715200.CSV\": \"CBS-232\"\n",
    "}\n",
    "base_nombrefich = \"indicadores_economicos\"\n",
    "\n",
    "nombres_ficheros = list()\n",
    "for fichero in ficheros:\n",
    "    nom_fichero = base_nombrefich + \"_\" + dict_traduccion[fichero] + \".csv\"\n",
    "    nombres_ficheros.append(nom_fichero)\n",
    "\n",
    "for i in range(0, len(ficheros)):\n",
    "    df_listado[i].to_csv(nombres_ficheros[i], sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "177455a7-2f6e-41bc-81f7-5505c3044ba3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "#Comprobar que los ficheros se han guardado correctamente\n",
    "listado_pwd = os.listdir()\n",
    "for fichero in nombres_ficheros:\n",
    "    print(fichero in listado_pwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e7f0e0-4851-4d7d-baab-c0db7adde128",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
